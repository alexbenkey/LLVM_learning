version: 2.1

# Define reusable commands
commands:
  install-llvm:
    description: "Install LLVM tools and dependencies"
    parameters:
      llvm-version:
        type: string
        default: "20"
    steps:
      - run:
          name: Install LLVM << parameters.llvm-version >> and dependencies
          command: |
            # Install prerequisites for adding APT repositories
            sudo apt-get update
            sudo apt-get install -y wget software-properties-common gnupg
            
            # Add LLVM APT repository
            wget -qO- https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -
            
            # Determine Ubuntu codename
            CODENAME=$(lsb_release -sc)
            echo "Detected Ubuntu codename: $CODENAME"
            
            # Add the appropriate LLVM repository
            echo "deb http://apt.llvm.org/$CODENAME/ llvm-toolchain-$CODENAME-<< parameters.llvm-version >> main" | sudo tee /etc/apt/sources.list.d/llvm.list
            
            # Update package lists with new repository
            sudo apt-get update
            
            # Install LLVM tools
            sudo apt-get install -y \
              llvm-<< parameters.llvm-version >> \
              clang-<< parameters.llvm-version >> \
              llvm-<< parameters.llvm-version >>-dev \
              llvm-<< parameters.llvm-version >>-tools \
              python3-pip
            
            # Create symlinks for version-less commands
            sudo update-alternatives --install /usr/bin/llvm-as llvm-as /usr/bin/llvm-as-<< parameters.llvm-version >> 100
            sudo update-alternatives --install /usr/bin/clang clang /usr/bin/clang-<< parameters.llvm-version >> 100
            sudo update-alternatives --install /usr/bin/FileCheck FileCheck /usr/bin/FileCheck-<< parameters.llvm-version >> 100
            sudo update-alternatives --install /usr/bin/opt opt /usr/bin/opt-<< parameters.llvm-version >> 100
            sudo update-alternatives --install /usr/bin/lli lli /usr/bin/lli-<< parameters.llvm-version >> 100
            
            # Install lit via pip
            pip3 install lit
            
            # Verify installations
            echo "=== Verifying LLVM Installation ==="
            echo "PATH: $PATH"
            echo "Available LLVM tools:"
            ls -la /usr/bin/*llvm* /usr/bin/*clang* /usr/bin/FileCheck* || true
            ls -la /usr/lib/llvm-<< parameters.llvm-version >>/bin/ || true
            
            echo "Tool versions:"
            llvm-as --version
            clang --version
            FileCheck --version
            opt --version
            lli --version
            lit --version
            
            echo "Testing basic functionality:"
            which llvm-as clang FileCheck opt lli
            echo 'define i32 @main() { ret i32 0 }' > test.ll
            llvm-as test.ll -o test.bc
            lli test.bc
            echo "Basic LLVM functionality verified"

  run-tests:
    description: "Run lit tests with proper reporting"
    parameters:
      output-dir:
        type: string
        default: "test-results"
    steps:
      - run:
          name: Create output directory
          command: mkdir -p << parameters.output-dir >>
      - run:
          name: Debug environment and test simple case
          command: |
            echo "Python version: $(python3 --version)"
            echo "Lit version: $(lit --version)"
            echo "PATH: $PATH"
            echo "Available tools:"
            which llvm-as lli opt FileCheck clang || true
            
            echo "Test simple case:"
            mkdir -p debug-test
            echo '; RUN: /bin/echo "test"' > debug-test/simple.test
            echo '; CHECK: test' >> debug-test/simple.test
            
            echo "Running simple test:"
            lit -vv debug-test/simple.test || echo "Simple test failed"
          when: always
      
      - run:
          name: Test with fallback configuration if needed
          command: |
            echo "Testing with alternative configuration"
            if [ -f lit.cfg.py.simple ]; then
              echo "Using simple configuration as fallback"
              cp lit.cfg.py lit.cfg.py.original
              cp lit.cfg.py.simple lit.cfg.py
              
              echo "Testing with simple config:"
              lit -vv tests/debug.test || echo "Even simple config failed"
              
              # Restore original
              mv lit.cfg.py.original lit.cfg.py
            else
              echo "No fallback config available"
            fi
          when: always

      - run:
          name: Run LLVM lit tests and exercises
          command: |
            # Run both tests and exercises with XML output for CircleCI
            echo "Running main tests..."
            lit -v --xunit-xml-output=<< parameters.output-dir >>/tests-results.xml tests/ || true
            
            echo "Running exercises..."
            lit -v --xunit-xml-output=<< parameters.output-dir >>/exercises-results.xml exercises/ || true
            
            # Combine results for CircleCI reporting
            echo "Combining results..."
            # Create a summary file
            echo "=== Test Summary ===" > << parameters.output-dir >>/summary.txt
            echo "Tests:" >> << parameters.output-dir >>/summary.txt
            grep -E "(Passed|Failed|Unsupported|Expected Failures):" << parameters.output-dir >>/tests-results.xml >> << parameters.output-dir >>/summary.txt || echo "No test results found" >> << parameters.output-dir >>/summary.txt
            echo "" >> << parameters.output-dir >>/summary.txt
            echo "Exercises:" >> << parameters.output-dir >>/summary.txt
            grep -E "(Passed|Failed|Unsupported|Expected Failures):" << parameters.output-dir >>/exercises-results.xml >> << parameters.output-dir >>/summary.txt || echo "No exercise results found" >> << parameters.output-dir >>/summary.txt
            
            cat << parameters.output-dir >>/summary.txt
          
          # Continue even if some tests fail - we want to see the results
          when: always
      
      - store_test_results:
          path: << parameters.output-dir >>
      
      - store_artifacts:
          path: << parameters.output-dir >>
          destination: test-and-exercise-results

# Define the jobs
jobs:
  # Basic test job
  test-basic:
    docker:
      - image: cimg/base:stable
    
    steps:
      - checkout
      - install-llvm
      - run-tests
  
  # Test with different LLVM versions
  test-llvm-versions:
    docker:
      - image: cimg/base:stable
    
    parameters:
      llvm-version:
        type: string
    
    steps:
      - checkout
      - install-llvm:
          llvm-version: << parameters.llvm-version >>
      - run-tests:
          output-dir: "test-results-llvm-<< parameters.llvm-version >>"

  # Comprehensive test with code coverage and performance metrics
  test-comprehensive:
    docker:
      - image: cimg/base:stable
    
    resource_class: medium+  # Use more resources for comprehensive testing
    
    steps:
      - checkout
      - install-llvm
      
      # Run tests and exercises with timing information
      - run:
          name: Run tests and exercises with performance metrics
          command: |
            mkdir -p test-results
            mkdir -p performance-results
            
            # Run tests with timing information
            echo "Running main tests with performance tracking..."
            lit --time-tests --xunit-xml-output=test-results/tests-results.xml tests/ | tee performance-results/tests-timing.log || true
            
            # Run exercises with timing information
            echo "Running exercises with performance tracking..."
            lit --time-tests --xunit-xml-output=test-results/exercises-results.xml exercises/ | tee performance-results/exercises-timing.log || true
            
            # Extract slowest tests for analysis
            echo "Analyzing performance..."
            grep -A 20 "Slowest Tests:" performance-results/tests-timing.log > performance-results/slow-tests.txt || true
            grep -A 20 "Slowest Tests:" performance-results/exercises-timing.log > performance-results/slow-exercises.txt || true
            
            # Create combined summary
            echo "=== Performance Summary ===" > performance-results/summary.txt
            echo "Tests:" >> performance-results/summary.txt
            tail -5 performance-results/tests-timing.log >> performance-results/summary.txt || true
            echo "" >> performance-results/summary.txt
            echo "Exercises:" >> performance-results/summary.txt
            tail -5 performance-results/exercises-timing.log >> performance-results/summary.txt || true
      
      - store_test_results:
          path: test-results
      
      - store_artifacts:
          path: test-results
          destination: test-results
      
      - store_artifacts:
          path: performance-results
          destination: performance-metrics
      

# Define workflows
workflows:
  version: 2
  
  # Main workflow - runs on every commit with LLVM-20 only
  test-and-build:
    jobs:
      - test-llvm-versions:
          name: test-llvm-20
          llvm-version: "20"
      
      # Run comprehensive tests only on main branch
      - test-comprehensive:
          filters:
            branches:
              only:
                - main
                - master
  
  # Nightly workflow - runs daily for long-term monitoring
  nightly:
    triggers:
      - schedule:
          cron: "0 2 * * *"  # Run at 2 AM UTC daily
          filters:
            branches:
              only:
                - main
                - master
    
    jobs:
      - test-comprehensive
